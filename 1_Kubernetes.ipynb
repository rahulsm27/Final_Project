{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "https://github.com/kelseyhightower/kubernetes-the-hard-way/blob/master/docs/08-bootstrapping-kubernetes-controllers.md\n",
    "\n",
    "https://docs.tigera.io/calico/latest/operations/calicoctl/install\n",
    "\n",
    "https://www.kubeflow.org/docs/components/pipelines/v1/installation/localcluster-deployment/\n",
    "\n",
    "https://www.kubeflow.org/docs/components/pipelines/v1/installation/standalone-deployment/\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "1. Create the VPC\n",
    "\n",
    "gcloud compute networks create example-k8s --subnet-mode custom\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "2. Create the k8s-nodes subnet in the example-k8s VPC network:\n",
    "\n",
    "gcloud compute networks subnets create k8s-nodes \\\n",
    "--network example-k8s \\\n",
    "--range 10.240.0.0/24\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\"\"\"\n",
    "3 Create a firewall rule that allows internal communication across TCP, UDP, ICMP and IP in IP (used for the Calico overlay):\n",
    "\n",
    "gcloud compute firewall-rules create example-k8s-allow-internal \\\n",
    "--allow tcp,udp,icmp,ipip \\\n",
    "--network example-k8s \\\n",
    "--source-ranges 10.240.0.0/24\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\"\"\"\n",
    "4.Create a firewall rule that allows external SSH, ICMP, and HTTPS:\n",
    "\n",
    "gcloud compute firewall-rules create example-k8s-allow-external \\\n",
    "--allow tcp:22,tcp:6443,icmp \\\n",
    "--network example-k8s \\\n",
    "--source-ranges 0.0.0.0/0\n",
    "\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "5. Create the controller VM\n",
    "\n",
    "\n",
    "gcloud compute instances create controller \\\n",
    "  --async \\\n",
    "  --boot-disk-size 200GB \\\n",
    "  --can-ip-forward \\\n",
    "  --image-family ubuntu-2004-lts \\\n",
    "  --image-project ubuntu-os-cloud \\\n",
    "  --machine-type n1-standard-2 \\\n",
    "  --private-network-ip 10.240.0.11 \\\n",
    "  --scopes compute-rw,storage-ro,service-management,service-control,logging-write,monitoring \\\n",
    "  --subnet k8s-nodes \\\n",
    "  --zone asia-east1-a \\\n",
    "  --tags example-k8s,controller \n",
    "\n",
    "  \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "6 Create three worker VMs.\n",
    "\n",
    "for i in 0 1 2; do\n",
    "  gcloud compute instances create worker-${i} \\\n",
    "  --async \\\n",
    "  --boot-disk-size 200GB \\\n",
    "  --can-ip-forward \\\n",
    "  --image-family ubuntu-2004-lts \\\n",
    "  --image-project ubuntu-os-cloud \\\n",
    "  --machine-type n1-standard-2 \\\n",
    "  --private-network-ip 10.240.0.2${i} \\\n",
    "  --scopes compute-rw,storage-ro,service-management,service-control,logging-write,monitoring \\\n",
    "  --subnet k8s-nodes \\\n",
    "  --zone asia-east1-a \\\n",
    "  --tags example-k8s,worker\n",
    "done\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "7 Install Docker on the controller VM and each worker VM. On each VM run:\n",
    "\n",
    "sudo apt update\n",
    "sudo apt install -y docker.io\n",
    "sudo systemctl enable docker.service\n",
    "sudo apt install -y apt-transport-https curl\n",
    "sudo swapoff -a && sudo sed -i '/ swap / s/^\\(.*\\)$/#\\1/g' /etc/fstab\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "KUBERNETES INSTALLATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "1 Install kubeadm, kubelet, and kubectl on each worker node and the controller node (see kubeadm docs for more details).\n",
    "\n",
    "curl -fsSL https://dl.k8s.io/apt/doc/apt-key.gpg | sudo apt-key add -\n",
    "cat <<EOF | sudo tee /etc/apt/sources.list.d/kubernetes.list\n",
    "deb https://apt.kubernetes.io/ kubernetes-xenial main\n",
    "EOF\n",
    "sudo apt-get update\n",
    "sudo apt-get install -y kubelet kubeadm kubectl\n",
    "sudo apt-mark hold kubelet kubeadm kubectl\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "2 Create the controller node of a new cluster.\n",
    "\n",
    "sudo kubeadm init --pod-network-cidr 192.168.0.0/16\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "# Should output somehting. This ahs to be used in step 4\n",
    "\n",
    "# sudo kubeadm join 10.240.0.11:6443 --token <token> --discovery-token-ca-cert-hash sha256:<hash>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "3 Set up kubectl for the Ubuntu user.\n",
    "\n",
    "Connect to the controller VM, and run the following commands:\n",
    "\n",
    "mkdir -p $HOME/.kube\n",
    "sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config\n",
    "sudo chown $(id -u):$(id -g) $HOME/.kube/config\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "4. Join your worker nodes to the controller node.\n",
    "Use the output of step 2\n",
    "\n",
    "sudo kubeadm join 10.240.0.11:6443 --token 40on7w.idqo4gzq8asfj6qa \\\n",
    "        --discovery-token-ca-cert-hash sha256:d48ee03910784df4c577ed69f22e1b2c1dd0fc3715010b0ced791a01083e763e\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CALICO INSTALLATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Calico Installation\n",
    "\n",
    "kubectl create -f https://raw.githubusercontent.com/projectcalico/calico/v3.27.0/manifests/tigera-operator.yaml\n",
    "\n",
    "curl https://raw.githubusercontent.com/projectcalico/calico/v3.27.0/manifests/custom-resources.yaml -O\n",
    "\n",
    "kubectl create -f custom-resources.yaml\n",
    "\n",
    "curl -L https://github.com/projectcalico/calico/releases/download/v3.27.0/calicoctl-linux-amd64 -o calicoctl\n",
    "\n",
    "chmod +x ./calicoctl\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "KUBEFLOW INSTALLATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "export PIPELINE_VERSION=2.0.5\n",
    "kubectl apply -k \"github.com/kubeflow/pipelines/manifests/kustomize/cluster-scoped-resources?ref=$PIPELINE_VERSION\"\n",
    "kubectl wait --for condition=established --timeout=60s crd/applications.app.k8s.io\n",
    "kubectl apply -k \"github.com/kubeflow/pipelines/manifests/kustomize/env/dev?ref=$PIPELINE_VERSION\"\n",
    "\n",
    "kubectl describe configmap inverse-proxy-config -n kubeflow | grep googleusercontent.com\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SOMEUSEFULL COMMANDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# kubectl get nodes\n",
    "# kubectl get all -A\n",
    "# kubectl describe nodes\n",
    "\n",
    "# sudo systemctl restart kubelet\n",
    "# kubectl get services -n kubeflow\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
